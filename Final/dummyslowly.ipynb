{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c0f55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Generating 1000 system monitoring records with gradual patterns and ~5% anomalies...\n",
      "‚ö†Ô∏è No anomalies were generated in this run\n",
      "‚úÖ Unsupervised dataset generated successfully!\n",
      "üìÅ Dataset saved as: system_monitoring_unsupervised.csv\n",
      "üìä Dataset shape: (2000, 11)\n",
      "üéØ Contains 0 anomalous records (details logged separately)\n",
      "\n",
      "üìã Sample of generated data (first 5 records):\n",
      "fw_load_avg_1_min fw_load_avg_5_min fw_load_avg_15_min  fw_cpu_used  mem_used  root_used  log_used  fw_total_alloc  total_rx_packets  total_tx_packets              created_at\n",
      "             0,13              0,22               0,18            0   7909922   10093214  10308128       645970186          19001258           1820113 2024-11-06 08:01:10.657\n",
      "             0,20              0,29               0,11            1   7908706   10093269  10308047       645873105          19003739           1820008 2024-11-06 08:03:37.727\n",
      "             0,00              0,28               0,21            0   7910752   10093227  10308305       646125338          19002663           1820022 2024-11-06 08:05:21.266\n",
      "             0,08              0,10               0,22            0   7906569   10093285  10308644       646044252          19002419           1820188 2024-11-06 08:06:49.318\n",
      "             0,10              0,01               0,18            0   7908655   10093147  10308169       645914832          19004798           1820171 2024-11-06 08:09:04.071\n",
      "\n",
      "üìã Sample of generated data (last 5 records - showing progression):\n",
      "fw_load_avg_1_min fw_load_avg_5_min fw_load_avg_15_min  fw_cpu_used  mem_used  root_used  log_used  fw_total_alloc  total_rx_packets  total_tx_packets              created_at\n",
      "             0,16              0,28               0,21            1   7927275   10093294  10316444       647701935          19150723           1824151 2024-11-09 02:30:39.991\n",
      "             0,22              0,28               0,24            0   7927219   10093249  10316417       647746752          19152207           1824077 2024-11-09 02:33:15.460\n",
      "             0,24              0,32               0,33            0   7925568   10093209  10315554       648346149          19152943           1824066 2024-11-09 02:36:22.953\n",
      "             0,35              0,18               0,26            0   7927725   10093214  10316392       647816327          19154150           1824112 2024-11-09 02:38:52.779\n",
      "             0,28              0,16               0,21            0   7928182   10093278  10315543       648337002          19153940           1824150 2024-11-09 02:39:52.147\n",
      "\n",
      "üìà Data statistics:\n",
      "Date range: 2024-11-06 08:01:10.657 to 2024-11-09 02:39:52.147\n",
      "Total records: 2000\n",
      "Load avg 1min range: 0.00 to 0.55\n",
      "CPU usage range: 0 to 2\n",
      "Memory usage range: 7,902,570 to 7,933,479\n",
      "RX packets range: 19,000,554 to 19,154,150\n",
      "TX packets range: 1,820,008 to 1,824,169\n",
      "\n",
      "üìà Showing gradual increase pattern:\n",
      "First record memory: 7,909,922\n",
      "Last record memory: 7,928,182\n",
      "Memory increase: 18,260\n",
      "First record RX packets: 19,001,258\n",
      "Last record RX packets: 19,153,940\n",
      "RX packets increase: 152,682\n",
      "\n",
      "üí° Dataset characteristics:\n",
      "‚úì Purely unsupervised - no labels or anomaly indicators in main dataset\n",
      "‚úì Gradual increase in memory usage over time\n",
      "‚úì Gradual increase in network packets over time\n",
      "‚úì Gradual increase in log usage over time\n",
      "‚úì Load averages stay low with small variations\n",
      "‚úì CPU usage mostly 0, occasionally 1-2\n",
      "‚úì Realistic timestamp progression\n",
      "‚úì Contains hidden anomalies (~5%) for detection algorithms\n",
      "‚úì Anomalies timeline logged separately in anomalies_list.csv\n",
      "üìù Both files use semicolon (;) as separator\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "import random\n",
    "\n",
    "# Tanpa set seed:\n",
    "rand_array = np.random.rand(3)\n",
    "rand_int = random.randint(0, 100)\n",
    "\n",
    "\n",
    "def generate_system_monitoring_data(n_samples=2000, anomaly_ratio=0.00):\n",
    "    \"\"\"\n",
    "    Generate synthetic system monitoring data with gradual increasing patterns and anomalies\n",
    "    Also track anomalies for separate logging\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base timestamp - mulai dari waktu yang lebih awal untuk menunjukkan progression\n",
    "    start_time = datetime(2024, 11, 6, 8, 0, 0)\n",
    "    \n",
    "    data = []\n",
    "    anomaly_logs = []  # List untuk menyimpan informasi anomali\n",
    "    anomaly_indices = set(np.random.choice(n_samples, int(n_samples * anomaly_ratio), replace=False))\n",
    "    \n",
    "    # Base values yang akan naik secara gradual\n",
    "    base_mem = 7910000\n",
    "    base_root = 10093200\n",
    "    base_log = 10308000\n",
    "    base_fw_alloc = 646000000\n",
    "    base_rx = 19000000\n",
    "    base_tx = 1820000\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # Time progression - interval yang lebih natural\n",
    "        time_offset = timedelta(\n",
    "            seconds=random.randint(30, 180),  # 30 detik sampai 3 menit\n",
    "            microseconds=random.randint(0, 999999)\n",
    "        )\n",
    "        current_time = start_time + timedelta(minutes=i * 2) + time_offset  # Setiap 2 menit rata-rata\n",
    "        \n",
    "        is_anomaly = i in anomaly_indices\n",
    "        \n",
    "        if is_anomaly:\n",
    "            # Generate anomalous data dan catat anomalinya\n",
    "            row, anomaly_info = generate_anomaly_row(current_time, i, n_samples, base_mem, base_root, base_log, base_fw_alloc, base_rx, base_tx)\n",
    "            \n",
    "            # Tambahkan informasi anomali ke log\n",
    "            anomaly_log_entry = {\n",
    "                'record_index': i,\n",
    "                'timestamp': current_time.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3],\n",
    "                'anomaly_type': anomaly_info['type'],\n",
    "                'description': anomaly_info['description'],\n",
    "                'affected_metrics': ', '.join(anomaly_info['affected_metrics']),\n",
    "                'severity': anomaly_info['severity']\n",
    "            }\n",
    "            anomaly_logs.append(anomaly_log_entry)\n",
    "        else:\n",
    "            # Generate normal data\n",
    "            row = generate_normal_row(current_time, i, n_samples, base_mem, base_root, base_log, base_fw_alloc, base_rx, base_tx)\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    # Sort by timestamp untuk memastikan urutan waktu yang benar\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values('created_at').reset_index(drop=True)\n",
    "    \n",
    "    # Create anomalies DataFrame\n",
    "    anomalies_df = pd.DataFrame(anomaly_logs)\n",
    "    if not anomalies_df.empty:\n",
    "        anomalies_df = anomalies_df.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    return df, anomalies_df, anomaly_indices\n",
    "\n",
    "def generate_normal_row(timestamp, index, total_samples, base_mem, base_root, base_log, base_fw_alloc, base_rx, base_tx):\n",
    "    \"\"\"Generate normal system metrics dengan gradual increase pattern\"\"\"\n",
    "    \n",
    "    # Progress factor (0 to 1) - menunjukkan seberapa jauh dalam timeline\n",
    "    progress = index / total_samples\n",
    "    \n",
    "    # Load averages - tetap rendah dengan variasi kecil\n",
    "    fw_load_avg_1_min = round(max(0, np.random.normal(0.15 + progress * 0.1, 0.1)), 2)\n",
    "    fw_load_avg_5_min = round(max(0, np.random.normal(0.18 + progress * 0.08, 0.08)), 2)\n",
    "    fw_load_avg_15_min = round(max(0, np.random.normal(0.20 + progress * 0.05, 0.05)), 2)\n",
    "    \n",
    "    # CPU usage - mostly 0, occasionally 1-2\n",
    "    cpu_base = 0 if random.random() < 0.7 else random.choice([1, 1, 2])\n",
    "    fw_cpu_used = cpu_base\n",
    "    \n",
    "    # Memory usage - gradual increase dengan noise\n",
    "    mem_increase = progress * 15000  # Naik sekitar 15KB selama periode\n",
    "    mem_used = int(base_mem + mem_increase + np.random.normal(0, 3000))\n",
    "    \n",
    "    # Root filesystem - hampir konstan dengan sedikit variasi\n",
    "    root_used = int(base_root + np.random.normal(0, 50))\n",
    "    \n",
    "    # Log usage - gradual increase (log files bertambah)\n",
    "    log_increase = progress * 8000  # Log naik sekitar 8KB\n",
    "    log_used = int(base_log + log_increase + np.random.normal(0, 500))\n",
    "    \n",
    "    # Firewall total allocation - gradual increase dengan variasi\n",
    "    fw_alloc_increase = progress * 2000000  # Naik sekitar 2MB\n",
    "    fw_total_alloc = int(base_fw_alloc + fw_alloc_increase + np.random.normal(0, 200000))\n",
    "    \n",
    "    # Network packets - gradual increase (traffic bertambah)\n",
    "    rx_increase = progress * 150000  # RX packets naik\n",
    "    tx_increase = progress * 4000    # TX packets naik\n",
    "    \n",
    "    total_rx_packets = int(base_rx + rx_increase + np.random.randint(0, 5000))\n",
    "    total_tx_packets = int(base_tx + tx_increase + np.random.randint(0, 200))\n",
    "    \n",
    "    return {\n",
    "        'fw_load_avg_1_min': f\"{fw_load_avg_1_min:.2f}\".replace('.', ','),\n",
    "        'fw_load_avg_5_min': f\"{fw_load_avg_5_min:.2f}\".replace('.', ','),\n",
    "        'fw_load_avg_15_min': f\"{fw_load_avg_15_min:.2f}\".replace('.', ','),\n",
    "        'fw_cpu_used': fw_cpu_used,\n",
    "        'mem_used': mem_used,\n",
    "        'root_used': root_used,\n",
    "        'log_used': log_used,\n",
    "        'fw_total_alloc': fw_total_alloc,\n",
    "        'total_rx_packets': total_rx_packets,\n",
    "        'total_tx_packets': total_tx_packets,\n",
    "        'created_at': timestamp.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "    }\n",
    "\n",
    "def generate_anomaly_row(timestamp, index, total_samples, base_mem, base_root, base_log, base_fw_alloc, base_rx, base_tx):\n",
    "    \"\"\"Generate anomalous system metrics and return anomaly information\"\"\"\n",
    "    \n",
    "    progress = index / total_samples\n",
    "    \n",
    "    anomaly_type = random.choice([\n",
    "        'high_load', 'high_cpu', 'memory_spike', 'disk_spike', \n",
    "        'network_spike', 'system_stress', 'resource_leak'\n",
    "    ])\n",
    "    \n",
    "    # Initialize anomaly info\n",
    "    anomaly_info = {\n",
    "        'type': anomaly_type,\n",
    "        'description': '',\n",
    "        'affected_metrics': [],\n",
    "        'severity': 'medium'\n",
    "    }\n",
    "    \n",
    "    if anomaly_type == 'high_load':\n",
    "        # Abnormally high load averages\n",
    "        fw_load_avg_1_min = round(np.random.uniform(2.0, 8.0), 2)\n",
    "        fw_load_avg_5_min = round(np.random.uniform(1.5, 4.0), 2)\n",
    "        fw_load_avg_15_min = round(np.random.uniform(1.0, 2.5), 2)\n",
    "        fw_cpu_used = random.randint(50, 95)\n",
    "        \n",
    "        anomaly_info['description'] = f'High system load detected: 1min={fw_load_avg_1_min}, CPU={fw_cpu_used}%'\n",
    "        anomaly_info['affected_metrics'] = ['fw_load_avg_1_min', 'fw_load_avg_5_min', 'fw_load_avg_15_min', 'fw_cpu_used']\n",
    "        anomaly_info['severity'] = 'high' if fw_load_avg_1_min > 5.0 else 'medium'\n",
    "        \n",
    "        # Base values dengan gradual increase\n",
    "        mem_used = int(base_mem + progress * 15000 + np.random.normal(0, 3000))\n",
    "        root_used = int(base_root + np.random.normal(0, 50))\n",
    "        log_used = int(base_log + progress * 8000 + np.random.normal(0, 500))\n",
    "        fw_total_alloc = int(base_fw_alloc + progress * 2000000 + np.random.normal(0, 200000))\n",
    "        total_rx_packets = int(base_rx + progress * 150000 + np.random.randint(0, 5000))\n",
    "        total_tx_packets = int(base_tx + progress * 4000 + np.random.randint(0, 200))\n",
    "        \n",
    "    elif anomaly_type == 'high_cpu':\n",
    "        # Normal load but very high CPU\n",
    "        fw_load_avg_1_min = round(max(0, np.random.normal(0.15 + progress * 0.1, 0.1)), 2)\n",
    "        fw_load_avg_5_min = round(max(0, np.random.normal(0.18 + progress * 0.08, 0.08)), 2)\n",
    "        fw_load_avg_15_min = round(max(0, np.random.normal(0.20 + progress * 0.05, 0.05)), 2)\n",
    "        fw_cpu_used = random.randint(80, 100)\n",
    "        \n",
    "        anomaly_info['description'] = f'High CPU usage detected: {fw_cpu_used}% with normal load average'\n",
    "        anomaly_info['affected_metrics'] = ['fw_cpu_used']\n",
    "        anomaly_info['severity'] = 'high' if fw_cpu_used > 90 else 'medium'\n",
    "        \n",
    "        mem_used = int(base_mem + progress * 15000 + np.random.normal(0, 3000))\n",
    "        root_used = int(base_root + np.random.normal(0, 50))\n",
    "        log_used = int(base_log + progress * 8000 + np.random.normal(0, 500))\n",
    "        fw_total_alloc = int(base_fw_alloc + progress * 2000000 + np.random.normal(0, 200000))\n",
    "        total_rx_packets = int(base_rx + progress * 150000 + np.random.randint(0, 5000))\n",
    "        total_tx_packets = int(base_tx + progress * 4000 + np.random.randint(0, 200))\n",
    "        \n",
    "    elif anomaly_type == 'memory_spike':\n",
    "        # Memory usage spike\n",
    "        fw_load_avg_1_min = round(max(0, np.random.normal(0.4, 0.2)), 2)\n",
    "        fw_load_avg_5_min = round(max(0, np.random.normal(0.35, 0.15)), 2)\n",
    "        fw_load_avg_15_min = round(max(0, np.random.normal(0.25, 0.1)), 2)\n",
    "        fw_cpu_used = random.randint(5, 25)\n",
    "        \n",
    "        # Memory spike - 2-3x normal\n",
    "        mem_used = int(np.random.uniform(15000000, 25000000))\n",
    "        \n",
    "        anomaly_info['description'] = f'Memory spike detected: {mem_used/1000000:.1f}MB (2-3x normal)'\n",
    "        anomaly_info['affected_metrics'] = ['mem_used', 'fw_load_avg_1_min']\n",
    "        anomaly_info['severity'] = 'high' if mem_used > 20000000 else 'medium'\n",
    "        \n",
    "        root_used = int(base_root + np.random.normal(0, 50))\n",
    "        log_used = int(base_log + progress * 8000 + np.random.normal(0, 500))\n",
    "        fw_total_alloc = int(base_fw_alloc + progress * 2000000 + np.random.normal(0, 200000))\n",
    "        total_rx_packets = int(base_rx + progress * 150000 + np.random.randint(0, 5000))\n",
    "        total_tx_packets = int(base_tx + progress * 4000 + np.random.randint(0, 200))\n",
    "        \n",
    "    elif anomaly_type == 'disk_spike':\n",
    "        # Disk usage anomaly\n",
    "        fw_load_avg_1_min = round(max(0, np.random.normal(0.8, 0.3)), 2)\n",
    "        fw_load_avg_5_min = round(max(0, np.random.normal(0.6, 0.2)), 2)\n",
    "        fw_load_avg_15_min = round(max(0, np.random.normal(0.4, 0.15)), 2)\n",
    "        fw_cpu_used = random.randint(15, 40)\n",
    "        \n",
    "        mem_used = int(base_mem + progress * 15000 + np.random.normal(0, 3000))\n",
    "        root_used = int(np.random.uniform(15000000, 20000000))  # Disk full\n",
    "        log_used = int(np.random.uniform(20000000, 30000000))   # Log explosion\n",
    "        \n",
    "        anomaly_info['description'] = f'Disk usage spike: Root={root_used/1000000:.1f}MB, Log={log_used/1000000:.1f}MB'\n",
    "        anomaly_info['affected_metrics'] = ['root_used', 'log_used', 'fw_load_avg_1_min']\n",
    "        anomaly_info['severity'] = 'critical' if root_used > 18000000 else 'high'\n",
    "        \n",
    "        fw_total_alloc = int(base_fw_alloc + progress * 2000000 + np.random.normal(0, 200000))\n",
    "        total_rx_packets = int(base_rx + progress * 150000 + np.random.randint(0, 5000))\n",
    "        total_tx_packets = int(base_tx + progress * 4000 + np.random.randint(0, 200))\n",
    "        \n",
    "    elif anomaly_type == 'network_spike':\n",
    "        # Network traffic anomaly\n",
    "        fw_load_avg_1_min = round(max(0, np.random.normal(0.6, 0.2)), 2)\n",
    "        fw_load_avg_5_min = round(max(0, np.random.normal(0.5, 0.15)), 2)\n",
    "        fw_load_avg_15_min = round(max(0, np.random.normal(0.3, 0.1)), 2)\n",
    "        fw_cpu_used = random.randint(10, 30)\n",
    "        \n",
    "        mem_used = int(base_mem + progress * 15000 + np.random.normal(0, 10000))\n",
    "        root_used = int(base_root + np.random.normal(0, 50))\n",
    "        log_used = int(base_log + progress * 8000 + np.random.normal(0, 500))\n",
    "        fw_total_alloc = int(np.random.uniform(800000000, 1200000000))  # High allocation\n",
    "        total_rx_packets = random.randint(25000000, 40000000)  # Traffic spike\n",
    "        total_tx_packets = random.randint(2500000, 4000000)\n",
    "        \n",
    "        anomaly_info['description'] = f'Network traffic spike: RX={total_rx_packets/1000000:.1f}M, TX={total_tx_packets/1000000:.1f}M packets'\n",
    "        anomaly_info['affected_metrics'] = ['total_rx_packets', 'total_tx_packets', 'fw_total_alloc']\n",
    "        anomaly_info['severity'] = 'high' if total_rx_packets > 35000000 else 'medium'\n",
    "        \n",
    "    elif anomaly_type == 'system_stress':\n",
    "        # Overall system stress\n",
    "        fw_load_avg_1_min = round(np.random.uniform(3.0, 6.0), 2)\n",
    "        fw_load_avg_5_min = round(np.random.uniform(2.0, 4.0), 2)\n",
    "        fw_load_avg_15_min = round(np.random.uniform(1.5, 3.0), 2)\n",
    "        fw_cpu_used = random.randint(70, 95)\n",
    "        \n",
    "        mem_used = int(np.random.uniform(12000000, 18000000))\n",
    "        root_used = int(np.random.uniform(12000000, 15000000))\n",
    "        log_used = int(np.random.uniform(15000000, 25000000))\n",
    "        fw_total_alloc = int(np.random.uniform(750000000, 950000000))\n",
    "        total_rx_packets = random.randint(22000000, 35000000)\n",
    "        total_tx_packets = random.randint(2200000, 3500000)\n",
    "        \n",
    "        anomaly_info['description'] = f'System stress: High load ({fw_load_avg_1_min}), CPU ({fw_cpu_used}%), Memory ({mem_used/1000000:.1f}MB)'\n",
    "        anomaly_info['affected_metrics'] = ['fw_load_avg_1_min', 'fw_cpu_used', 'mem_used', 'root_used', 'log_used']\n",
    "        anomaly_info['severity'] = 'critical'\n",
    "        \n",
    "    else:  # resource_leak\n",
    "        # Gradual resource leak pattern\n",
    "        fw_load_avg_1_min = round(np.random.uniform(1.0, 2.5), 2)\n",
    "        fw_load_avg_5_min = round(np.random.uniform(1.2, 2.8), 2)\n",
    "        fw_load_avg_15_min = round(np.random.uniform(1.5, 3.2), 2)\n",
    "        fw_cpu_used = random.randint(25, 60)\n",
    "        \n",
    "        # Resource leak - lebih tinggi dari normal tapi tidak extreme\n",
    "        mem_used = int(base_mem + progress * 15000 + np.random.uniform(3000000, 6000000))\n",
    "        root_used = int(base_root + np.random.normal(0, 50))\n",
    "        log_used = int(base_log + progress * 8000 + np.random.normal(0, 500))\n",
    "        fw_total_alloc = int(base_fw_alloc + progress * 2000000 + np.random.uniform(30000000, 100000000))\n",
    "        total_rx_packets = int(base_rx + progress * 150000 + np.random.randint(0, 5000))\n",
    "        total_tx_packets = int(base_tx + progress * 4000 + np.random.randint(0, 200))\n",
    "        \n",
    "        anomaly_info['description'] = f'Resource leak detected: Memory +{(mem_used-base_mem)/1000000:.1f}MB, FW alloc +{(fw_total_alloc-base_fw_alloc)/1000000:.1f}MB'\n",
    "        anomaly_info['affected_metrics'] = ['mem_used', 'fw_total_alloc', 'fw_load_avg_15_min']\n",
    "        anomaly_info['severity'] = 'medium'\n",
    "    \n",
    "    row_data = {\n",
    "        'fw_load_avg_1_min': f\"{fw_load_avg_1_min:.2f}\".replace('.', ','),\n",
    "        'fw_load_avg_5_min': f\"{fw_load_avg_5_min:.2f}\".replace('.', ','),\n",
    "        'fw_load_avg_15_min': f\"{fw_load_avg_15_min:.2f}\".replace('.', ','),\n",
    "        'fw_cpu_used': fw_cpu_used,\n",
    "        'mem_used': mem_used,\n",
    "        'root_used': root_used,\n",
    "        'log_used': log_used,\n",
    "        'fw_total_alloc': fw_total_alloc,\n",
    "        'total_rx_packets': total_rx_packets,\n",
    "        'total_tx_packets': total_tx_packets,\n",
    "        'created_at': timestamp.strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "    }\n",
    "    \n",
    "    return row_data, anomaly_info\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"üöÄ Generating 1000 system monitoring records with gradual patterns and ~5% anomalies...\")\n",
    "df, anomalies_df, anomaly_indices = generate_system_monitoring_data()\n",
    "\n",
    "# Save complete dataset to CSV with semicolon separator\n",
    "output_file = 'system_monitoring_unsupervised.csv'\n",
    "df.to_csv(output_file, sep=';', index=False)\n",
    "\n",
    "# Save anomalies log to separate CSV\n",
    "anomalies_file = 'anomalies_list.csv'\n",
    "if not anomalies_df.empty:\n",
    "    anomalies_df.to_csv(anomalies_file, sep=';', index=False)\n",
    "    print(f\"üéØ Anomalies log saved as: {anomalies_file}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No anomalies were generated in this run\")\n",
    "\n",
    "print(f\"‚úÖ Unsupervised dataset generated successfully!\")\n",
    "print(f\"üìÅ Dataset saved as: {output_file}\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")\n",
    "print(f\"üéØ Contains {len(anomalies_df)} anomalous records (details logged separately)\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìã Sample of generated data (first 5 records):\")\n",
    "print(df.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nüìã Sample of generated data (last 5 records - showing progression):\")\n",
    "print(df.tail(5).to_string(index=False))\n",
    "\n",
    "# Display anomalies summary if any exist\n",
    "if not anomalies_df.empty:\n",
    "    print(f\"\\nüö® Anomalies Summary ({len(anomalies_df)} total):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Group by anomaly type\n",
    "    anomaly_counts = anomalies_df['anomaly_type'].value_counts()\n",
    "    for anomaly_type, count in anomaly_counts.items():\n",
    "        print(f\"  {anomaly_type}: {count} occurrences\")\n",
    "    \n",
    "    # Group by severity\n",
    "    severity_counts = anomalies_df['severity'].value_counts()\n",
    "    print(f\"\\nSeverity Distribution:\")\n",
    "    for severity, count in severity_counts.items():\n",
    "        print(f\"  {severity}: {count} occurrences\")\n",
    "    \n",
    "    print(f\"\\nüìã Sample anomalies (first 3):\")\n",
    "    print(anomalies_df[['timestamp', 'anomaly_type', 'severity', 'description']].head(3).to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà Data statistics:\")\n",
    "print(f\"Date range: {df['created_at'].min()} to {df['created_at'].max()}\")\n",
    "print(f\"Total records: {len(df)}\")\n",
    "\n",
    "# Convert comma decimal to dot for numeric analysis\n",
    "df_numeric = df.copy()\n",
    "for col in ['fw_load_avg_1_min', 'fw_load_avg_5_min', 'fw_load_avg_15_min']:\n",
    "    df_numeric[col] = df_numeric[col].str.replace(',', '.').astype(float)\n",
    "\n",
    "print(f\"Load avg 1min range: {df_numeric['fw_load_avg_1_min'].min():.2f} to {df_numeric['fw_load_avg_1_min'].max():.2f}\")\n",
    "print(f\"CPU usage range: {df['fw_cpu_used'].min()} to {df['fw_cpu_used'].max()}\")\n",
    "print(f\"Memory usage range: {df['mem_used'].min():,} to {df['mem_used'].max():,}\")\n",
    "print(f\"RX packets range: {df['total_rx_packets'].min():,} to {df['total_rx_packets'].max():,}\")\n",
    "print(f\"TX packets range: {df['total_tx_packets'].min():,} to {df['total_tx_packets'].max():,}\")\n",
    "\n",
    "print(\"\\nüìà Showing gradual increase pattern:\")\n",
    "print(f\"First record memory: {df.iloc[0]['mem_used']:,}\")\n",
    "print(f\"Last record memory: {df.iloc[-1]['mem_used']:,}\")\n",
    "print(f\"Memory increase: {df.iloc[-1]['mem_used'] - df.iloc[0]['mem_used']:,}\")\n",
    "\n",
    "print(f\"First record RX packets: {df.iloc[0]['total_rx_packets']:,}\")\n",
    "print(f\"Last record RX packets: {df.iloc[-1]['total_rx_packets']:,}\")\n",
    "print(f\"RX packets increase: {df.iloc[-1]['total_rx_packets'] - df.iloc[0]['total_rx_packets']:,}\")\n",
    "\n",
    "print(\"\\nüí° Dataset characteristics:\")\n",
    "print(\"‚úì Purely unsupervised - no labels or anomaly indicators in main dataset\")\n",
    "print(\"‚úì Gradual increase in memory usage over time\")\n",
    "print(\"‚úì Gradual increase in network packets over time\") \n",
    "print(\"‚úì Gradual increase in log usage over time\")\n",
    "print(\"‚úì Load averages stay low with small variations\")\n",
    "print(\"‚úì CPU usage mostly 0, occasionally 1-2\")\n",
    "print(\"‚úì Realistic timestamp progression\")\n",
    "print(\"‚úì Contains hidden anomalies (~5%) for detection algorithms\")\n",
    "print(\"‚úì Anomalies timeline logged separately in anomalies_list.csv\")\n",
    "print(\"üìù Both files use semicolon (;) as separator\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
